{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import  KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler ,MinMaxScaler, PowerTransformer,QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def merge(station_data, measurement_data):\n",
    "    station_data[\"QoS\"] = np.where(station_data[\"QoS\"] == \"accep\", \"acceptable\", station_data[\"QoS\"])\n",
    "    station_data[\"QoS\"] = np.where(station_data[\"QoS\"] == \"maitennce\", \"maintenance\", station_data[\"QoS\"])\n",
    "\n",
    "    station_data['revision'] = station_data['revision'].apply(lambda x: pd.Timestamp(x).timestamp())\n",
    "\n",
    "    station_data['latitude'] = station_data['latitude'].round(5)\n",
    "    station_data['longitude'] = station_data['longitude'].round(5)\n",
    "\n",
    "    station_data[\"station\"] = np.where(station_data[\"station\"] == \"T‚Äôaebaek\", \"Taebaek\", station_data[\"station\"])\n",
    "    station_data[\"station\"] = np.where(station_data[\"station\"] == \"'Ali Sabieh\", \"Ali Sabieh\", station_data[\"station\"])\n",
    "    station_data[\"station\"] = np.where(station_data[\"station\"] == \"Oktyabr‚Äôskiy\", \"Oktyabrsk\", station_data[\"station\"])\n",
    "    station_data[\"station\"] = np.where(station_data[\"station\"] == \"Roslavl‚Äô\", \"Roslavl\", station_data[\"station\"])\n",
    "    station_data[\"station\"] = np.where(station_data[\"station\"] == \"Dyat‚Äôkovo\", \"Dyatkovo\", station_data[\"station\"])\n",
    "\n",
    "    station_data = station_data.groupby(by=['latitude', 'longitude'], group_keys=False).apply(lambda x: x.loc[x['revision']==x['revision'].max()])\n",
    "    result_table = pd.merge(station_data, measurement_data, on=['latitude', 'longitude'], how='inner')\n",
    "\n",
    "    return result_table"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    column_names_ = []\n",
    "    for column_name_ in list(data.columns.values):\n",
    "        column_names_.append(column_name_)\n",
    "\n",
    "    column_names_.remove('warning')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[column_names_], data['warning'])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def power_transform(X, column_name):\n",
    "    data = X[column_name].values\n",
    "    data = data.reshape((len(data),1))\n",
    "\n",
    "    data_trans = PowerTransformer(method='yeo-johnson', standardize=True).fit_transform(data)\n",
    "    X[column_name] = data_trans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def transform(X, y=None, pipeline=None):\n",
    "    p = 1\n",
    "    if pipeline is None:\n",
    "        p = 0\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X['station'])\n",
    "    X['station'] = le.transform(X['station'])\n",
    "\n",
    "    le.fit(X['code'])\n",
    "    X['code'] = le.transform(X['code'])\n",
    "\n",
    "    le.fit(X['QoS'])\n",
    "    X['QoS'] = le.transform(X['QoS'])\n",
    "\n",
    "    column_names_t = []\n",
    "\n",
    "    for column_name_t in list(X.columns.values):\n",
    "        column_names_t.append(column_name_t)\n",
    "\n",
    "    chemical_names_t = copy.deepcopy(column_names_t)\n",
    "\n",
    "    passthroughs_t = ['QoS', 'station', 'code', 'latitude', 'longitude', 'revision']\n",
    "\n",
    "    for passthrough in passthroughs_t:\n",
    "        chemical_names_t.remove(passthrough)\n",
    "\n",
    "    if y is not None: # ak y nie je None potom mame trenovacie data\n",
    "        column_names_t.append('warning')\n",
    "        passthroughs_t.append('warning')\n",
    "        X['warning'] = y\n",
    "        X.dropna(subset=['warning'], inplace=True) # trenovacie data bez warning mozeme vyhodit\n",
    "\n",
    "\n",
    "    column_names_t = passthroughs_t + chemical_names_t\n",
    "\n",
    "    for i in chemical_names_t:\n",
    "        if abs(X[i].skew()) > 1.5:\n",
    "            power_transform(X, i)\n",
    "\n",
    "    if p == 0:\n",
    "        pipe = make_pipeline(\n",
    "            KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean'),\n",
    "            QuantileTransformer(output_distribution=\"normal\", random_state=0, n_quantiles=1000),\n",
    "            StandardScaler()\n",
    "        )\n",
    "\n",
    "        ct = ColumnTransformer([('passthrough', 'passthrough', passthroughs_t), ('num_transformer', pipe, chemical_names_t)])\n",
    "\n",
    "        pipeline = Pipeline([('column_transformer', ct)])\n",
    "\n",
    "    pipeline.fit(X)\n",
    "    transformed_df = pd.DataFrame(pipeline.transform(X), columns=column_names_t).copy()\n",
    "\n",
    "    X.to_csv('output.csv', index=False)\n",
    "\n",
    "    if y is None:\n",
    "        if p == 0:\n",
    "            return transformed_df, pipeline\n",
    "        if p == 1:\n",
    "            return transformed_df\n",
    "    else:\n",
    "        column_names_t.remove('warning')\n",
    "        if p == 0:\n",
    "            return transformed_df[column_names_t], transformed_df['warning'], pipeline\n",
    "        if p == 1:\n",
    "            return transformed_df[column_names_t], transformed_df['warning']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "d = merge(pd.read_csv(\"data/stations.csv\", sep='\\t'), pd.read_csv(\"data/measurements.csv\", sep='\\t'))\n",
    "X_train, X_test, y_train, y_test = split(d)\n",
    "\n",
    "X_train, y_train, pipeline_ = transform(X_train, y_train)\n",
    "\n",
    "X_train.to_csv('transformed_data/X_train.csv', index=False)\n",
    "y_train.to_csv('transformed_data/y_train.csv', index=False)\n",
    "\n",
    "X_test, y_test = transform(X_test, y_test, pipeline_)\n",
    "\n",
    "X_test.to_csv('transformed_data/X_test.csv', index=False)\n",
    "y_test.to_csv('transformed_data/y_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
